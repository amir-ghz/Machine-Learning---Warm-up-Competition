{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "train = pd.read_csv(os.path.join('./input', 'train.csv'))\n",
    "test = pd.read_csv(os.path.join('./input', 'test.csv'))\n",
    "\n",
    "# starting the preprocessing for each data column\n",
    "\n",
    "def name_preproc(train, test):\n",
    "    for i in [train, test]:\n",
    "        i['Name_Len'] = i['Name'].apply(lambda x: len(x))\n",
    "        i['Name_Title'] = i['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x: x.split()[0])\n",
    "        del i['Name']\n",
    "    return train, test\n",
    "\n",
    "def age_preproc(train, test):\n",
    "    for i in [train, test]:\n",
    "        i['Age_Null_Flag'] = i['Age'].apply(lambda x: 1 if pd.isnull(x) else 0)\n",
    "        data = train.groupby(['Name_Title', 'Pclass'])['Age']\n",
    "        i['Age'] = data.transform(lambda x: x.fillna(x.mean()))\n",
    "    return train, test\n",
    "\n",
    "def family_size_preproc(train, test):\n",
    "    for i in [train, test]:\n",
    "        i['family_size_preproc'] = np.where((i['SibSp']+i['Parch']) == 0 , 'Solo',\n",
    "                           np.where((i['SibSp']+i['Parch']) <= 3,'Nuclear', 'Big'))\n",
    "        del i['SibSp']\n",
    "        del i['Parch']\n",
    "    return train, test\n",
    "\n",
    "def ticket_grouped_preproc(train, test):\n",
    "    for i in [train, test]:\n",
    "        i['Ticket_Lett'] = i['Ticket'].apply(lambda x: str(x)[0])\n",
    "        i['Ticket_Lett'] = i['Ticket_Lett'].apply(lambda x: str(x))\n",
    "        i['Ticket_Lett'] = np.where((i['Ticket_Lett']).isin(['1', '2', '3', 'S', 'P', 'C', 'A']), i['Ticket_Lett'],\n",
    "                                   np.where((i['Ticket_Lett']).isin(['W', '4', '7', '6', 'L', '5', '8']),\n",
    "                                            'Low_ticket', 'Other_ticket'))\n",
    "        i['Ticket_Len'] = i['Ticket'].apply(lambda x: len(x))\n",
    "        del i['Ticket']\n",
    "    return train, test\n",
    "\n",
    "def cabin_preproc(train, test):\n",
    "    for i in [train, test]:\n",
    "        i['Cabin_Letter'] = i['Cabin'].apply(lambda x: str(x)[0])\n",
    "        del i['Cabin']\n",
    "    return train, test\n",
    "\n",
    "def cabin_num_preproc(train, test):\n",
    "    for i in [train, test]:\n",
    "        i['Cabin_num1'] = i['Cabin'].apply(lambda x: str(x).split(' ')[-1][1:])\n",
    "        i['Cabin_num1'].replace('an', np.NaN, inplace = True)\n",
    "        i['Cabin_num1'] = i['Cabin_num1'].apply(lambda x: int(x) if not pd.isnull(x) and x != '' else np.NaN)\n",
    "        i['Cabin_num'] = pd.qcut(train['Cabin_num1'],3)\n",
    "    train = pd.concat((train, pd.get_dummies(train['Cabin_num'], prefix = 'Cabin_num')), axis = 1)\n",
    "    test = pd.concat((test, pd.get_dummies(test['Cabin_num'], prefix = 'Cabin_num')), axis = 1)\n",
    "    del train['Cabin_num']\n",
    "    del test['Cabin_num']\n",
    "    del train['Cabin_num1']\n",
    "    del test['Cabin_num1']\n",
    "    return train, test\n",
    "\n",
    "def embarked_preproc(train, test):\n",
    "    for i in [train, test]:\n",
    "        i['Embarked'] = i['Embarked'].fillna('S')\n",
    "    return train, test\n",
    "\n",
    "test['Fare'].fillna(train['Fare'].mean(), inplace = True)\n",
    "\n",
    "\n",
    "def dummies(train, test, columns = ['Pclass', 'Sex', 'Embarked', 'Ticket_Lett', 'Cabin_Letter', 'Name_Title', 'family_size_preproc']):\n",
    "    for column in columns:\n",
    "        train[column] = train[column].apply(lambda x: str(x))\n",
    "        test[column] = test[column].apply(lambda x: str(x))\n",
    "        good_cols = [column+'_'+i for i in train[column].unique() if i in test[column].unique()]\n",
    "        train = pd.concat((train, pd.get_dummies(train[column], prefix = column)[good_cols]), axis = 1)\n",
    "        test = pd.concat((test, pd.get_dummies(test[column], prefix = column)[good_cols]), axis = 1)\n",
    "        del train[column]\n",
    "        del test[column]\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def drop(train, test, bye = ['PassengerId']):\n",
    "    for i in [train, test]:\n",
    "        for z in bye:\n",
    "            del i[z]\n",
    "    return train, test\n",
    "\n",
    "\n",
    "train = pd.read_csv(os.path.join('../input', 'train.csv'))\n",
    "test = pd.read_csv(os.path.join('../input', 'test.csv'))\n",
    "train, test = name_preproc(train, test)\n",
    "train, test = age_preproc(train, test)\n",
    "train, test = cabin_num_preproc(train, test)\n",
    "train, test = cabin_preproc(train, test)\n",
    "train, test = embarked_preproc(train, test)\n",
    "train, test = family_size_preproc(train, test)\n",
    "test['Fare'].fillna(train['Fare'].mean(), inplace = True)\n",
    "train, test = ticket_grouped_preproc(train, test)\n",
    "train, test = dummies(train, test, columns = ['Pclass', 'Sex', 'Embarked', 'Ticket_Lett', 'Cabin_Letter', 'Name_Title', 'family_size_preproc'])\n",
    "train, test = drop(train, test)\n",
    "\n",
    "print(len(train.columns))\n",
    "\n",
    "\n",
    "\n",
    "# Changing number of trees to 600\n",
    "\n",
    "rf = RandomForestClassifier(criterion='gini', \n",
    "                             n_estimators=600,\n",
    "                             min_samples_split=10,\n",
    "                             min_samples_leaf=1,\n",
    "                             max_features='auto',\n",
    "                             oob_score=True,\n",
    "                             random_state=1,\n",
    "                             n_jobs=-1)\n",
    "rf.fit(train.iloc[:, 1:], train.iloc[:, 0])\n",
    "print(\"%.4f\" % rf.oob_score_)\n",
    "\n",
    "\n",
    "predictions = rf.predict(test)\n",
    "predictions = pd.DataFrame(predictions, columns=['Survived'])\n",
    "test = pd.read_csv(os.path.join('../input', 'test.csv'))\n",
    "predictions = pd.concat((test.iloc[:, 0], predictions), axis = 1)\n",
    "predictions.to_csv('sub2.csv', sep=\",\", index = False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
